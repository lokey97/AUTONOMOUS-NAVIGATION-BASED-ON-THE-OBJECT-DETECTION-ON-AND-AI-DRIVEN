from ultralytics import YOLO
import torch
import cv2
import numpy as np

# =============================================================================
# 1. Define Custom YOLOv8 Architecture
# =============================================================================
# This custom configuration incorporates modifications as described in your paper:
# - A modified backbone with additional SPPF for enhanced multi-scale feature extraction.
# - Adjustments in the head layers.
custom_yaml = """
# YOLOv8 custom model architecture based on paper details for KLH Campus dataset
nc: 3  # Number of classes (e.g., pedestrians, vehicles, static objects); adjust as needed
depth_multiple: 0.33
width_multiple: 0.50

# Backbone configuration with SPPF integration
backbone:
  - [ -1, 1, Focus, [64, 3] ]
  - [ -1, 1, Conv, [128, 3, 2] ]
  - [ -1, 3, BottleneckCSP, [128] ]
  - [ -1, 1, Conv, [256, 3, 2] ]
  - [ -1, 6, BottleneckCSP, [256] ]
  - [ -1, 1, Conv, [512, 3, 2] ]
  - [ -1, 3, BottleneckCSP, [512] ]
  - [ -1, 1, SPPF, [512, 5] ]  # Spatial Pyramid Pooling Fast module

# Head configuration for final feature refinement and prediction
head:
  - [ -1, 3, BottleneckCSP, [512, False] ]
  - [ -1, 1, Conv, [256, 1, 1] ]
  - [ -1, 1, nn.Upsample, [None, 2, 'nearest'] ]
  - [ -1, 1, Concat, [] ]
  - [ -1, 3, BottleneckCSP, [256, False] ]
  - [ -1, 1, Conv, [128, 1, 1] ]
  - [ -1, 1, nn.Upsample, [None, 2, 'nearest'] ]
  - [ -1, 1, Concat, [] ]
  - [ -1, 3, BottleneckCSP, [128, False] ]
  - [ -1, 1, Conv, [256, 3, 2] ]
  - [ -1, 1, Concat, [] ]
  - [ -1, 3, BottleneckCSP, [256, False] ]
  - [ -1, 1, Conv, [512, 3, 2] ]
  - [ -1, 1, Concat, [] ]
  - [ -1, 3, BottleneckCSP, [512, False] ]
"""

# Save the custom YAML to a file so YOLO API can load it.
yaml_path = 'yolov8_custom.yaml'
with open(yaml_path, 'w') as f:
    f.write(custom_yaml)

# =============================================================================
# 2. Load and Customize the YOLOv8 Model
# =============================================================================
# Load the custom YOLO model architecture defined above.
model = YOLO(yaml_path)

# Set device (GPU if available, else CPU)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# =============================================================================
# 3. Train the Model on Your Dataset
# =============================================================================
# Prepare a data configuration file (data.yaml) with the following format:
#
# train: path/to/dataset/images/train
# val:   path/to/dataset/images/val
# nc:    3               # number of classes (should match 'nc' in custom YAML)
# names: ['class1', 'class2', 'class3']  # adjust class names as needed
#
# Replace 'path/to/data.yaml' below with the correct path to your data.yaml file.
model.train(data="path/to/data.yaml", epochs=50, imgsz=640, batch=16, device=device)

# =============================================================================
# 4. Run Inference on a Video/Webcam Feed
# =============================================================================
# After training, you can test the model using a webcam (or a video file).
cap = cv2.VideoCapture(0)  # Change to a video file path if needed

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # Run inference
    results = model(frame)
    
    # Process and display results
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = box.conf[0].item()
            cls = int(box.cls[0].item())
            label = f'{model.names[cls]} {conf:.2f}'
            
            # Draw bounding box and label on the frame
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    cv2.imshow('YOLOv8 Custom Detection', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()